# ================================
# QWEENONE v2.0 CONFIGURATION
# ================================

# ================================
# API KEYS
# ================================
# OpenAI (GPT models)
OPENAI_API_KEY=sk-your-openai-key-here

# Anthropic (Claude models)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# OpenRouter (100+ models)
OPENROUTER_API_KEY=sk-or-your-openrouter-key-here

# Google AI (Gemini)
GOOGLE_API_KEY=your-google-key-here

# Cohere
COHERE_API_KEY=your-cohere-key-here

# ================================
# REDIS CONFIGURATION
# ================================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
REDIS_SSL=false

# ================================
# RABBITMQ CONFIGURATION
# ================================
RABBITMQ_HOST=localhost
RABBITMQ_PORT=5672
RABBITMQ_USER=qweenone
RABBITMQ_PASS=qweenone_secret
RABBITMQ_VHOST=/
RABBITMQ_EXCHANGE=qweenone_agents

# ================================
# POSTGRESQL CONFIGURATION (Prefect)
# ================================
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=prefect
POSTGRES_USER=prefect
POSTGRES_PASSWORD=prefect_secret

# Connection URL for Prefect
PREFECT_API_DATABASE_CONNECTION_URL=postgresql+asyncpg://prefect:prefect_secret@localhost:5432/prefect

# ================================
# FEATURE FLAGS
# ================================
# Enable/disable modern components
USE_PREFECT=true
USE_ROMA=true
ENABLE_DESKTOP_AUTOMATION=false
ENABLE_BROWSER_AUTOMATION=true
ENABLE_LITELLM=true

# A2A Backend: memory | redis | rabbitmq
A2A_BACKEND=redis

# ================================
# SYSTEM CONFIGURATION
# ================================
LOG_LEVEL=INFO
PYTHONUNBUFFERED=1

# Workflow Configuration
CONCURRENT_TASK_LIMIT=5
DEFAULT_TASK_TIMEOUT=3600
ENABLE_TASK_RETRY=true
MAX_RETRY_COUNT=3

# Automation Configuration
SCREENSHOT_DIR=/tmp/qweenone_screenshots
BROWSER_HEADLESS=true
BROWSER_TIMEOUT=30000

# ================================
# MONITORING & OBSERVABILITY
# ================================
PROMETHEUS_ENABLED=true
PROMETHEUS_PORT=9090

GRAFANA_ENABLED=true
GRAFANA_PORT=3000

# ================================
# PREFECT CONFIGURATION
# ================================
PREFECT_SERVER_API_HOST=0.0.0.0
PREFECT_SERVER_API_PORT=4200
PREFECT_UI_API_URL=http://localhost:4200/api

# ================================
# DEVELOPMENT SETTINGS
# ================================
# Enable debug mode (verbose logging, not for production)
DEBUG_MODE=false

# Enable performance profiling
ENABLE_PROFILING=false

# Enable request tracing
ENABLE_TRACING=false

# ================================
# SECURITY SETTINGS
# ================================
# JWT secret for API authentication (if using API)
JWT_SECRET=your-secret-key-here

# Session timeout (minutes)
SESSION_TIMEOUT=60

# ================================
# RESOURCE LIMITS
# ================================
# Max concurrent workflows
MAX_CONCURRENT_WORKFLOWS=10

# Max message queue size
MAX_MESSAGE_QUEUE_SIZE=10000

# Max automation history
MAX_AUTOMATION_HISTORY=1000

# ================================
# OPTIONAL SERVICES
# ================================
# Scalar API documentation
SCALAR_ENABLED=true
SCALAR_PORT=5050

# ================================
# NOTES
# ================================
# 1. Copy this file to .env and fill in your values
# 2. Never commit .env to git (already in .gitignore)
# 3. Use strong passwords in production
# 4. Enable only features you need
# 5. For production, use secrets management (Vault, AWS Secrets Manager, etc.)
